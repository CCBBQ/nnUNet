# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ti42ReiRxu2QKdZesBGr6o5n1WF-t1Pl
"""

from google.colab import drive
import os

drive.mount('/content/drive')
os.chdir('/content/drive/MyDrive/ML-Quiz-3DMedImg')

!pip install pytorch-lightning

import shutil
import json
import numpy as np
import torch
import torch.nn as nn
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import f1_score
import nibabel as nib
import torch.nn.functional as F
from collections import Counter
from sklearn.utils.class_weight import compute_class_weight
from scipy.ndimage import gaussian_filter
import SimpleITK as sitk
import matplotlib.pyplot as plt
import os
from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer
from nnunetv2.utilities.plans_handling.plans_handler import PlansManager
from batchgenerators.utilities.file_and_folder_operations import load_json, join

# 1. 安装依赖
!pip install -q --upgrade pip
!pip install -q numpy nibabel scikit-image scikit-learn tqdm matplotlib SimpleITK medpy

# 安装nnunetv2（官方最新版本）

!pip install git+https://github.com/CCBBQ/nnUNet.git@master

# 设置 nnU-Net 环境变量
os.environ['nnUNet_raw'] = '/content/drive/MyDrive/ML-Quiz-3DMedImg'
os.environ['nnUNet_preprocessed'] = '/content/drive/MyDrive/ML-Quiz-3DMedImg/processed'
os.environ['nnUNet_results'] = '/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation'

# 创建对应目录
!mkdir -p /content/drive/MyDrive/ML-Quiz-3DMedImg
!mkdir -p /content/drive/MyDrive/ML-Quiz-3DMedImg/processed
!mkdir -p /content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation

!which nnUNetv2_train

"""#一次性代码

"""

# === 3. 准备原始数据为nnUNet结构（替换路径为你上传的数据）===
def prepare_nnunet_dataset(original_data_dir, nnunet_dataset_dir):
    os.makedirs(nnunet_dataset_dir, exist_ok=True)
    imagesTr = os.path.join(nnunet_dataset_dir, "imagesTr")
    labelsTr = os.path.join(nnunet_dataset_dir, "labelsTr")
    imagesVal = os.path.join(nnunet_dataset_dir, "imagesVal")
    labelsVal = os.path.join(nnunet_dataset_dir, "labelsVal")
    imagesTs = os.path.join(nnunet_dataset_dir, "imagesTs")

    for d in [imagesTr, labelsTr, imagesVal, labelsVal, imagesTs]:
        os.makedirs(d, exist_ok=True)
    def copy_imgs_labels_recursive(src_dir, img_out, label_out):
        for root, dirs, files in os.walk(src_dir):
            for f in files:
                full_path = os.path.join(root, f)
                if f.endswith("_0000.nii.gz"):
                    shutil.copy(full_path, os.path.join(img_out, f))
                elif f.endswith(".nii.gz") and not f.endswith("_0000.nii.gz"):
                    shutil.copy(full_path, os.path.join(label_out, f))

    # 处理训练集和验证集
    copy_imgs_labels_recursive(os.path.join(original_data_dir, "train"), imagesTr, labelsTr)
    copy_imgs_labels_recursive(os.path.join(original_data_dir, "validation"), imagesVal, labelsVal)

    # 处理测试集（只有图像）
    for f in os.listdir(os.path.join(original_data_dir, "test")):
        if f.endswith("_0000.nii.gz"):
            shutil.copy(os.path.join(os.path.join(original_data_dir, "test"), f), os.path.join(imagesTs, f))

    print("✅ 数据准备完毕！")
    print(f"imagesTr: {len(os.listdir(imagesTr))} 张图像")
    print(f"labelsTr: {len(os.listdir(labelsTr))} 个标签")
    print(f"imagesVal: {len(os.listdir(imagesVal))} 张图像")
    print(f"labelsVal: {len(os.listdir(labelsVal))} 个标签")
    print(f"imagesTs: {len(os.listdir(imagesTs))} 张测试图像")


    # 创建 dataset.json
    training_files = sorted([f for f in os.listdir(imagesTr) if f.endswith('_0000.nii.gz')])
    test_files = sorted([f for f in os.listdir(imagesTs) if f.endswith('_0000.nii.gz')])
    dataset_json = {
        "name": "PancreasSeg",
        "description": "Pancreas CT Segmentation",
        "tensorImageSize": "3D",
        "labels": {
          "0": "background",
          "1": "pancreas",
          "2": "lesion"
        },
        "channel_names": {
        "0": "CT"
        },
        "file_ending": ".nii.gz",
        "numTraining": len(training_files),
        "numTest": len(test_files),
        "training": [
            {
                "image": f"./imagesTr/{f}",
                "label": f"./labelsTr/{f.replace('_0000.nii.gz', '.nii.gz')}"
            } for f in training_files
        ],
        "test": [f"./imagesTs/{f}" for f in test_files]
    }
    with open(os.path.join(nnunet_dataset_dir, "dataset.json"), 'w') as f:
        json.dump(dataset_json, f, indent=4)

# 调用函数：你可以上传到 "/content/original_data"
prepare_nnunet_dataset("/content/drive/MyDrive/ML-Quiz-3DMedImg", "/content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer")

json_path = "/content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer/dataset.json"

with open(json_path, "r") as f:
    data = json.load(f)

# 确保labels字段是dict且含0-background
data["labels"] = {
    "background": "0",
    "pancreas": "1",
    "lesion": "2"
}

# 补充缺失字段
if "channel_names" not in data:
    data["channel_names"] = {
        "0": "CT"
    }

if "file_ending" not in data:
    data["file_ending"] = ".nii.gz"

with open(json_path, "w") as f:
    json.dump(data, f, indent=4)

print("dataset.json updated!")

import numpy as np
labels_folder = "/content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer/labelsVal"

for filename in os.listdir(labels_folder):
    if filename.endswith(".nii.gz"):
        filepath = os.path.join(labels_folder, filename)
        print(f"Processing {filepath} ...")
        # 读取标签文件
        img = nib.load(filepath)
        data = img.get_fdata()

        # 四舍五入并转成整数
        data_int = np.rint(data).astype(np.uint8)

        # 创建新nii图像，保留原有仿射矩阵和头信息
        new_img = nib.Nifti1Image(data_int, img.affine, img.header)

        # 保存覆盖原文件
        nib.save(new_img, filepath)

print("标签数据修正完成！")

"""#segmantation

"""

# === 4. 预处理（含训练和验证集）===
!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity

!nnUNetv2_train Dataset001_PancreasCancer 3d_fullres 0

# 路径设置
ckpt_path = "/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/Dataset001_PancreasCancer/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth"
save_path = "/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/Dataset001_PancreasCancer/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0//checkpoint_pruned.pth"

# 加载 checkpoint
checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)
state_dict = checkpoint['network_weights']  # nnUNetv2 key

# 简单“通道剪枝”：这里仅做权重缩放（保留结构），可以替换为你自定义的稀疏剪枝
def prune_weights(state_dict, ratio=0.3):
    pruned_dict = {}
    for k, v in state_dict.items():
        if "weight" in k and v.dim() >= 4:  # 卷积层
            out_channels = v.size(0)
            prune_num = int(out_channels * ratio)
            if prune_num >= out_channels:  # 避免剪光
                prune_num = out_channels - 1
            pruned_v = v[prune_num:]  # 简单丢弃前 N 个通道
            pruned_dict[k] = pruned_v
        else:
            pruned_dict[k] = v
    return pruned_dict

# 应用剪枝
pruned_state_dict = prune_weights(state_dict, ratio=0.2)  # 剪掉 20%

# 更新 checkpoint
checkpoint['network_weights'] = pruned_state_dict

# 保存
torch.save(checkpoint, save_path)
print(f"✅ Saved pruned checkpoint to {save_path}")

!nnUNetv2_train Dataset001_Pancreas 3d_fullres 0 \
  --pretrained_weights /content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/Dataset001_PancreasCancer/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0//checkpoint_pruned.pth

# === 5. 训练模型（默认3D fullres，fold 0）===
!nnUNetv2_train 001 3d_fullres 0 --c

!nnUNetv2_predict -d 001 -i /content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer/imagesTs \
  -o /content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/test_predictions -f 0 -c 3d_fullres

plt.savefig()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# === 7. 可视化分割结果 ===
def show_segmentation(image_path, prediction_path, slice_index=None):
    image = nib.load(image_path).get_fdata()
    prediction = nib.load(prediction_path).get_fdata()

    if slice_index is None:
        slice_index = image.shape[2] // 2

    img_slice = image[:, :, slice_index]
    pred_slice = prediction[:, :, slice_index]

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(img_slice.T)
    plt.title("Original Image")

    plt.subplot(1, 2, 2)
    plt.imshow(img_slice.T)
    plt.imshow(pred_slice.T)
    plt.title("Segmentation Overlay")
    plt.show()

show_segmentation('/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/test_predictions/quiz_108.nii.gz','/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/test_predictions/quiz_129.nii.gz')

"""#Classification"""

!pip install torch

plan_p = '/content/drive/MyDrive/ML-Quiz-3DMedImg/processed/Dataset001_PancreasCancer/nnUNetPlans.json'
dataset_p = '/content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer/dataset.json'
checkpoint_p = '/content/drive/MyDrive/ML-Quiz-3DMedImg/segmentation/Dataset001_PancreasCancer/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_final.pth'

'''plans = load_json(plan_p)
dataset_json = load_json(dataset_p)'''
plans_manager = PlansManager(plans)

# 3. 初始化trainer
trainer = nnUNetTrainer(
    plans=PlansManager('/content/drive/MyDrive/ML-Quiz-3DMedImg/processed/Dataset001_PancreasCancer/nnUNetPlans.json'),  # 这里直接传递plans字典，不是plans_manager
    configuration="3d_fullres",  # 根据您的模型选择"2d"或"3d"
    fold=0,
    dataset_json=load_json('/content/drive/MyDrive/ML-Quiz-3DMedImg/Dataset001_PancreasCancer/dataset.json'),
)

# 4. 初始化网络
trainer.initialize()
# 5. 加载检查点（如果需要）
checkpoint_path = checkpoint_p
trainer.load_checkpoint(checkpoint_path)

# 获取预训练encoder
encoder = trainer.network.encoder

# 预处理类，缩放、归一化
from torchmetrics.classification import F1Score
class NiftiPreprocessing:
    def __init__(self, mode='train', target_size=(176, 176, 88)):
        self.mode = mode
        self.target_size = target_size
    def pad_to_min_size(self, img_np, target_size=None):
        """
        将 numpy 图像数组在每个轴方向上向后 pad 到至少 target_size。
        输入图像为 (D, H, W)
        """
        if target_size is None:
            target_size = self.target_size

        current_size = img_np.shape
        pad_width = []
        for i in range(3):  # D, H, W
            total_pad = max(target_size[i] - current_size[i], 0)
            before = total_pad // 2
            after = total_pad - before
            pad_width.append((before, after))
        padded = np.pad(img_np, pad_width, mode='constant', constant_values=0)
        return padded
    def resample_image(self, img_np):
        # 转为 SimpleITK 图像
        img_sitk = sitk.GetImageFromArray(img_np)
        original_size = np.array(img_sitk.GetSize(), dtype=np.int32)
        original_spacing = np.array(img_sitk.GetSpacing())
        target_size = np.array(self.target_size)

        # 计算新的spacing，保证物理空间大小一致
        new_spacing = (original_spacing * original_size) / target_size

        resample = sitk.ResampleImageFilter()
        resample.SetOutputSpacing(new_spacing.tolist())
        resample.SetSize(target_size.tolist())
        resample.SetOutputDirection(img_sitk.GetDirection())
        resample.SetOutputOrigin(img_sitk.GetOrigin())
        resample.SetInterpolator(sitk.sitkLinear)  # 图像用线性插值

        resampled = resample.Execute(img_sitk)
        resampled_np = sitk.GetArrayFromImage(resampled)
        return resampled_np

    def __call__(self, img: np.ndarray):
        img = img.astype(np.float32)
        # 如果是彩色图像 (D, H, W, C)，先转成灰度
        if img.ndim == 4 and img.shape[-1] == 3:
            # 用平均值转灰度：RGB → Gray
            img = img.mean(axis=-1)
        elif img.ndim == 3 and img.shape[0] == 3:
            # 可能是 (3, D, H) 或 (3, H, W)，取决于来源
            img = img.mean(axis=0)  # 或者 axis=0 看实际格式

        # 先 pad 保证大小最小
        img = self.pad_to_min_size(img, self.target_size)

        # 用SimpleITK做重采样
        img = self.resample_image(img)

        # 转成tensor，格式 (C=1, D, H, W)
        img = torch.from_numpy(img).unsqueeze(0)

        # 归一化，只对非零体素做均值方差归一
        nonzero = img[img > 0]
        if nonzero.numel() > 0:
            mean = nonzero.mean()
            std = nonzero.std()
            if std > 0:
                img = (img - mean) / std
            else:
                img = img - mean
        return img

def denoise_image(image_np, sigma=1):
    return gaussian_filter(image_np, sigma=sigma)
# Dataset
class MyDataset(Dataset):
    def __init__(self, file_list, label_list, mode='train'):
        self.files = file_list
        self.labels = label_list
        self.mode = mode
        self.preprocess = NiftiPreprocessing(mode)
        print(f"Class distribution: {Counter(label_list)}")

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        path = self.files[idx]
        label = self.labels[idx]
        img = nib.load(path).get_fdata()

        # 加入去噪步骤
        img = denoise_image(img, sigma=1)

        img = self.preprocess(img)
        label = torch.tensor(label, dtype=torch.long)
        return img, label

# Lightning Module
class SEBlock(nn.Module):
    def __init__(self, channel, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel),
            nn.Sigmoid()
        )
    def forward(self, x):
        b, c, _, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1, 1)
        return x * y.expand_as(x)

class MyModel(pl.LightningModule):
    def __init__(self, encoder, num_classes, class_weights=None):
        super().__init__()
        self.encoder = encoder
        self.val_outputs = []
        self.f1 = F1Score(task='multiclass', num_classes=3, average='macro')

        # 假设 encoder 返回一个list或tuple，包含多尺度特征
        # 这里拿两个尺度：倒数第二层和最后一层
        with torch.no_grad():
            dummy = torch.randn(1, 1, 128, 128, 128)
            features = encoder(dummy)
            if isinstance(features, (list, tuple)):
                feat_low = features[-2]
                feat_high = features[-1]
            else:
                raise ValueError("Encoder must return multiple feature maps for multi-scale fusion.")

            self.se_low = SEBlock(feat_low.shape[1])
            self.se_high = SEBlock(feat_high.shape[1])

            pooled_low = nn.AdaptiveAvgPool3d(1)(feat_low)
            pooled_high = nn.AdaptiveAvgPool3d(1)(feat_high)
            self.feature_dim = pooled_low.shape[1] + pooled_high.shape[1]

            print(f"Multi-scale fused feature dim: {self.feature_dim}")


        # 网络结构
        self.pool = nn.AdaptiveAvgPool3d(1)  # [B, C, 1, 1, 1] -> [B, C]
        self.classifier = nn.Sequential(
                  nn.Linear(self.feature_dim, 1024),
                  nn.BatchNorm1d(1024),
                  nn.ReLU(),
                  nn.Dropout(0.5),

                  nn.Linear(1024, 512),
                  nn.BatchNorm1d(512),
                  nn.ReLU(),
                  nn.Dropout(0.4),

                  nn.Linear(512, 256),
                  nn.BatchNorm1d(256),
                  nn.ReLU(),
                  nn.Dropout(0.3),

                  nn.Linear(256, 128),
                  nn.BatchNorm1d(128),
                  nn.ReLU(),
                  nn.Dropout(0.2),

                  nn.Linear(128, num_classes)
              )

        if class_weights is not None:
            self.criterion = nn.CrossEntropyLoss(weight=class_weights)
        else:
            self.criterion = nn.CrossEntropyLoss()

        self.val_preds = []
        self.val_labels = []
        self.train_preds = []
        self.train_labels = []

    def forward(self, x):
        features = self.encoder(x)
        if not isinstance(features, (list, tuple)):
            raise ValueError("Encoder must return multiple feature maps for multi-scale fusion.")

        feat_low = features[-2]
        feat_high = features[-1]

        # SE块增强
        feat_low = self.se_low(feat_low)
        feat_high = self.se_high(feat_high)

        # 池化 + 展平
        pooled_low = self.pool(feat_low).view(x.size(0), -1)
        pooled_high = self.pool(feat_high).view(x.size(0), -1)

        fused = torch.cat([pooled_low, pooled_high], dim=1)
        logits = self.classifier(fused)
        return logits

    def training_step(self, batch, batch_idx):
        imgs, labels = batch
        logits = self(imgs)
        loss = self.criterion(logits, labels)
        preds = torch.argmax(logits, dim=1)
        self.train_preds.append(preds.cpu())
        self.train_labels.append(labels.cpu())
        self.log("train_loss", loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy(logits, y)
        preds = torch.argmax(logits, dim=1)

        f1 = self.f1(preds, y)

        self.log('val_loss', loss, prog_bar=True, on_epoch=True)
        self.log('val_f1', f1, prog_bar=True, on_epoch=True)  # <-- This is required

        return loss

    def on_train_epoch_end(self):
        all_preds = torch.cat(self.train_preds)
        all_labels = torch.cat(self.train_labels)
        macro_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='macro')
        print(f"Train macro F1: {macro_f1:.4f}")
        # 打印每类预测数
        pred_counts = Counter(all_preds.numpy())
        for cls in range(self.classifier[-1].out_features):
            print(f"Train predicted count for class {cls}: {pred_counts.get(cls, 0)}")
        self.train_preds.clear()
        self.train_labels.clear()

    def on_validation_epoch_end(self):
        if not self.val_outputs:
            return

        all_preds = torch.cat([x['preds'] for x in self.val_outputs])
        all_labels = torch.cat([x['labels'] for x in self.val_outputs])

        val_f1 = f1_score(all_labels.cpu(), all_preds.cpu(), average='macro')
        val_acc = (all_preds == all_labels).float().mean()

        self.log("val_f1", val_f1, prog_bar=True)
        self.log("val_acc", val_acc, prog_bar=False)

        print(f"\nVal F1: {val_f1:.4f}, Acc: {val_acc:.4f}")
        for cls in range(self.classifier[-1].out_features):
            print(f"Class {cls}: Pred={sum(all_preds == cls)}, True={sum(all_labels == cls)}")

        # 清空缓存
        self.val_outputs.clear()

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW([
            {'params': self.encoder.parameters(), 'lr': 1e-4},  # 更低的学习率
            {'params': self.classifier.parameters(), 'lr': 1e-3}
        ], weight_decay=1e-4)

        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=20, verbose=True
        )
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'monitor': 'val_f1'
            }
        }


# ------------------------------
# 先对文件名和标签做筛选，保留含"0000"的样本
def filter_files_by_keyword(files, labels, keyword='0000'):
    filtered_files = []
    filtered_labels = []
    for f, l in zip(files, labels):
        if keyword in f:
            filtered_files.append(f)
            filtered_labels.append(l)
    return filtered_files, filtered_labels

train_files_filtered, train_labels_filtered = filter_files_by_keyword(train_files, train_labels, '0000')
val_files_filtered, val_labels_filtered = filter_files_by_keyword(val_files, val_labels, '0000')

# 假设特征维度和类别数，改成你自己网络对应的
feature_dim = 320 * 8 * 4 * 4
num_classes = 3

# 假设 train_labels 是一个 list 或 numpy array
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_labels),
    y=train_labels
)

class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)
if torch.cuda.is_available():
    class_weights_tensor = class_weights_tensor.cuda()
model = MyModel(encoder, num_classes=3, class_weights=class_weights_tensor)


# 准备数据集
train_dataset = MyDataset(train_files_filtered, train_labels_filtered, mode='train')
val_dataset = MyDataset(val_files_filtered, val_labels_filtered, mode='val')

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)


from pytorch_lightning.callbacks import ModelCheckpoint

# 定义checkpoint回调，保存val_f1最好的模型
checkpoint_callback = ModelCheckpoint(
    monitor='val_f1',       # 监控val_f1指标
    mode='max',             # val_f1越大越好
    save_top_k=1,           # 只保存最好的1个模型
    filename='best-f1-{epoch:02d}-{val_f1:.4f}',
    save_weights_only=False  # 只保存权重
)

# Trainer，加入callbacks参数
trainer = pl.Trainer(
    max_epochs=100,
    accelerator="gpu" if torch.cuda.is_available() else "cpu",
    devices=1 if torch.cuda.is_available() else None,
    log_every_n_steps=10,
    callbacks=[checkpoint_callback],  # 加入checkpoint回调
)

trainer.fit(model, train_loader, val_loader)

import torch
x = torch.randn(1, 1, 10, 10, 10).cuda()
conv3d = torch.nn.Conv3d(1, 1, kernel_size=3, padding=1).cuda()
out = conv3d(x)
print(out.shape)

# 假设 test_files 是测试集文件路径列表

class TestDataset(torch.utils.data.Dataset):
    def __init__(self, file_list):
        self.files = file_list
        self.preprocess = NiftiPreprocessing(mode='test')

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        path = self.files[idx]
        img = nib.load(path).get_fdata()
        img = self.preprocess(img)
        return img

test_dataset = TestDataset('/content/drive/MyDrive/ML-Quiz-3DMedImg/test')
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)
filename='best-f1-{epoch:02d}-{val_f1:.4f}'
model = MyModel.load_from_checkpoint(checkpoint_callback.best_model_path, encoder=encoder, num_classes=3, class_weights=class_weights_tensor)
model.eval()

if torch.cuda.is_available():
    model.cuda()

all_preds = []
with torch.no_grad():
    for imgs in test_loader:
        if torch.cuda.is_available():
            imgs = imgs.cuda()
        logits = model(imgs)
        preds = torch.argmax(logits, dim=1)
        all_preds.extend(preds.cpu().tolist())

print("预测结果：", all_preds)